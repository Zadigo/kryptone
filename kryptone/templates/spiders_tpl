"""
This is the main module for creating
a spider that will crawl an entire website

    1. Define a start url from which the spider
       should start gathering additional urls to crawl
    
    2. Define a set of actions that the spider should do
       on each visited page. You can also define actions that
       will be executed just after the spider has visited a page
       for example clicking on a button in a cookies modal

    3. Run python manage.py start MyFirstCrawler
"""

from kryptone.base import SiteCrawler


class MyFirstCrawler(SiteCrawler):
    start_url = None

    def post_visit_actions(self, **kwargs):
        pass

    def run_actions(self, current_url, **kwargs):
        pass
